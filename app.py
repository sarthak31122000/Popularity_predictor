import streamlit as st
import pandas as pd
import pickle
import requests
import numpy as np
from bs4 import BeautifulSoup 
import nltk

print('\nBe patience downloading the files will take time....\n')
nltk.download('punkt')

print('punkt downloading completed!\n')

nltk.download('stopwords')
print('\nstopwords downloading completed! Application is running.')

header={'Accept':'application/vnd.github.mercy-preview+json',
'visibility':'PUBLIC',
"Authorization": "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"
}

st.markdown(f'''<h1 style="text-align:center;color:#2C3333;font-family:Monospace;font-size:54px;margin-bottom:20px">
                    Popularity Indicator <br>Predictor</h1>''', unsafe_allow_html=True)

st.image('media/original.gif')

with open('pretrained_model/objs.pkl','rb') as f:  
    store_tag, vocabulary, vocab, word_dict = pickle.load(f)
with open('pretrained_model/train_model.pkl','rb') as f: 
    model = pickle.load(f)

def perc(tags):
    """This function returns the ratio of the total of tags in repository

    Args:
        tags (List): Tags that are in the repository

    Returns:
        sum_of_perc*100 [float]: 
    """
    sum_of_perc=0
    
    for tag in tags:
        # print(tag)
        if tag in store_tag:
            sum_of_perc += (store_tag[tag]/vocabulary)
    
    return (sum_of_perc*100)

def string_num(text):
    """Mapping the word with the corresponding number

    Args:
        text (List): List of words

    Returns:
        string_numbers (int): Total of mapped integer corresponding to the words in text
    """
    string_numbers = 0
    for string in text:
        if string in word_dict:
            string_numbers += word_dict[string]
    return string_numbers


keys=['forks','watchers','open_issues_count','topics','description','language']
form = st.form(key='my_form')
user_name = form.text_input("Username")
repo_name= form.text_input("Repo name")
submit_button = form.form_submit_button(label='Predict')

if submit_button:
    try:
        user_name=user_name.strip()
        repo_name=repo_name.strip()
        request=requests.get('https://api.github.com/repos/'+user_name+'/'+repo_name,headers=header)
        data=request.json()
        # print(data)
        
        dataf=[data[k] for k in keys]
        if str(data['license']).lower()=='none':
            license=0
        else:
            license=1
            
        request=requests.get('https://api.github.com/repos/'+user_name+'/'+repo_name+'/contributors',headers=header)
        dat=request.json()
        contributors=len(dat)
        dataf.append(contributors)
        dataf.append(license)
        df=pd.DataFrame([dataf],columns=['fork','watch','issue','tags','description','most_used_lang','contributers','license'])
        
        df['most_used_lang']=df['most_used_lang'].str.lower()
        df['description']=df['description'].str.lower()
        df['tag_ratio']=df['tags'].apply(perc).astype(float)
        
        if df['description'][0]:
            text=nltk.word_tokenize(df['description'][0])
            df['desc_to_num'] = string_num(text)
        else:
            df['desc_to_num']=0
        
        word_counts_for_language = {unique_word: [0] for unique_word in vocab}
        
        df['most_used_lang']=df['most_used_lang'].str.split()
        for word in df['most_used_lang']:
            if word[0] in word_counts_for_language:
                word_counts_for_language[word[0].lower()][0] += 1
        
        first_kpi, second_kpi, third_kpi,fourth= st.beta_columns(4)


        with first_kpi:
            st.markdown("**Issues**")
            number1 = data['open_issues']
            st.markdown(f"<h1 style=' color: #1B2430;'>{number1}</h1>", unsafe_allow_html=True)
        
        with second_kpi:
            st.markdown("**Most Used Language**")
            number2 = data['language']
            st.markdown(f"<h1 style=' color: #1B2430;'>{number2}</h1>", unsafe_allow_html=True)
        
        with third_kpi:
            st.markdown("**Forks**")
            number3 = data['forks']
            st.markdown(f"<h1 style=' color: #1B2430;'>{number3}</h1>", unsafe_allow_html=True)

        with fourth:
            st.markdown("**TAGs**")
            if data['topics']:
                number4 = data['topics']
            else:
                number4='Not mentioned'
            st.markdown(f"<h1 style=' color: #1B2430;'>{number4}</h1>", unsafe_allow_html=True)

        st.markdown(f"<hr>", unsafe_allow_html=True)
        first, sec= st.beta_columns(2)


        with first:
            st.markdown("**Description**")
            number1 = data['description']
            st.markdown(f"<p style=' color: #1B2430;'>{number1}</p>", unsafe_allow_html=True)

        with sec:
            st.markdown("**License**")
            st.markdown(f"<p style=' color: #1B2430;'>{data['license']}</p>", unsafe_allow_html=True)
        
        st.markdown(f"<hr>", unsafe_allow_html=True)
        language_col=pd.DataFrame(word_counts_for_language)
        test_set=pd.concat([df,language_col],axis=1)
        test_set.drop(['tags','description','language','no','most_used_lang'],axis=1,inplace=True)
        
        pred=int(model.predict(test_set)[0])
        if pred>1000:
            pred=str(float(pred)/1000)+'k'
        st.success("Your Repo can achieve Popularity  : "+str(pred)+' ðŸŒŸ')
    
    except:
        st.error("Sorry cannot find the repo, please Try again!!!")
